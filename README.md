# Project-4
Project Overview
Welcome to the Strokes project! This collaborative effort aims to visually show stroke data and utilize machine learning to accurately predict who carries the greatest risk of experiencing strokes with various factors in mind.

#Project Goals
1.	Data Collection: The data is cleaned, normalized, and standardized prior to modeling data.

2.	Create Data Database: Create a database in SQL for model to utilize.  

3.	Develop a python script: Intent to initialize, train, and evaluate a model that is at least 75% classification accuracy.

4.	Data Model Optimization: The model optimization and evaluation process showing iterative changes made to the model and the resulting changes in model performance is documented in either a CSV/Excel table and/or in the Python script itself.

5.	Data Visualization - Provide meaningful visualizations to help the viewers understand the data analysis.

6.	Model Prediction: Train model to acutely predict based on the data set who is most at risk to experience a stroke.

7.	Analysis: Explore, analyze, and use our program to create focus groups to compare stroke frequencies in various demographics.

#Methodology
Data Collection: Gather stoke data from a source.

Data Preprocessing: Clean, prepare, and format the collected data for analysis.

Insert Data into Database: Place cleaned data into SQL Server.

Create Model to make Accurate Predictions: Connect the database to the model and train said model.

Data Visualization: Create informative visualizations using Tableau to illustrate the data facts from our CSV.

Interpretation and Prediction: Observe trends and use program to make predictions.

Data Sources
The following data sources were used for this analysis:
https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset

Built with SQL, Tableau, and Spark.

#Authors:
Aime√© Galindo: GitHub | LinkedIn
Ehsan Aref Adib: GitHub | LinkedIn
Natalie Binder: GitHub | LinkedIn
Nathaniel Cervantez: GitHub | LinkedIn
